2025-02-08 11:01:13,369 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.1.4:41491'
2025-02-08 11:01:13,374 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.1.4:35469'
2025-02-08 11:01:13,376 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.1.4:42535'
2025-02-08 11:01:13,378 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.1.4:44489'
2025-02-08 11:01:13,379 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.26.1.4:32851'
2025-02-08 11:01:14,414 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-tdk4r52m', purging
2025-02-08 11:01:14,416 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-7efxlzid', purging
2025-02-08 11:01:14,417 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-q0jqmooe', purging
2025-02-08 11:01:14,417 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-51gvke0l', purging
2025-02-08 11:01:14,422 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-g6ig625w', purging
2025-02-08 11:01:14,423 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-srt6l94j', purging
2025-02-08 11:01:14,424 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-m4fli1m4', purging
2025-02-08 11:01:14,425 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-43ea68wt', purging
2025-02-08 11:01:14,426 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-ndsr23ae', purging
2025-02-08 11:01:14,426 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-g1ypgv5_', purging
2025-02-08 11:01:14,427 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-u42fuqih', purging
2025-02-08 11:01:14,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-lhb_uuco', purging
2025-02-08 11:01:14,428 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-vuspmi0f', purging
2025-02-08 11:01:14,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-vfa5w1_y', purging
2025-02-08 11:01:14,429 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-nbbgcxms', purging
2025-02-08 11:01:15,212 - distributed.worker - INFO -       Start worker at:     tcp://172.26.1.4:37389
2025-02-08 11:01:15,212 - distributed.worker - INFO -          Listening to:     tcp://172.26.1.4:37389
2025-02-08 11:01:15,212 - distributed.worker - INFO -           Worker name:           SLURMCluster-7-4
2025-02-08 11:01:15,212 - distributed.worker - INFO -          dashboard at:           172.26.1.4:40565
2025-02-08 11:01:15,212 - distributed.worker - INFO - Waiting to connect to:   tcp://10.42.239.61:44245
2025-02-08 11:01:15,212 - distributed.worker - INFO - -------------------------------------------------
2025-02-08 11:01:15,212 - distributed.worker - INFO -               Threads:                          2
2025-02-08 11:01:15,212 - distributed.worker - INFO -                Memory:                  18.63 GiB
2025-02-08 11:01:15,212 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lpq8rith
2025-02-08 11:01:15,212 - distributed.worker - INFO - -------------------------------------------------
2025-02-08 11:01:15,255 - distributed.worker - INFO -       Start worker at:     tcp://172.26.1.4:45535
2025-02-08 11:01:15,255 - distributed.worker - INFO -          Listening to:     tcp://172.26.1.4:45535
2025-02-08 11:01:15,255 - distributed.worker - INFO -           Worker name:           SLURMCluster-7-1
2025-02-08 11:01:15,255 - distributed.worker - INFO -          dashboard at:           172.26.1.4:41183
2025-02-08 11:01:15,255 - distributed.worker - INFO - Waiting to connect to:   tcp://10.42.239.61:44245
2025-02-08 11:01:15,255 - distributed.worker - INFO - -------------------------------------------------
2025-02-08 11:01:15,256 - distributed.worker - INFO -               Threads:                          2
2025-02-08 11:01:15,256 - distributed.worker - INFO -                Memory:                  18.63 GiB
2025-02-08 11:01:15,256 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wijwe5rx
2025-02-08 11:01:15,256 - distributed.worker - INFO - -------------------------------------------------
2025-02-08 11:01:15,454 - distributed.worker - INFO -       Start worker at:     tcp://172.26.1.4:33393
2025-02-08 11:01:15,454 - distributed.worker - INFO -          Listening to:     tcp://172.26.1.4:33393
2025-02-08 11:01:15,454 - distributed.worker - INFO -           Worker name:           SLURMCluster-7-0
2025-02-08 11:01:15,454 - distributed.worker - INFO -          dashboard at:           172.26.1.4:41787
2025-02-08 11:01:15,454 - distributed.worker - INFO - Waiting to connect to:   tcp://10.42.239.61:44245
2025-02-08 11:01:15,454 - distributed.worker - INFO - -------------------------------------------------
2025-02-08 11:01:15,454 - distributed.worker - INFO -               Threads:                          2
2025-02-08 11:01:15,454 - distributed.worker - INFO -                Memory:                  18.63 GiB
2025-02-08 11:01:15,454 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v3k_c3f2
2025-02-08 11:01:15,454 - distributed.worker - INFO - -------------------------------------------------
2025-02-08 11:01:15,461 - distributed.worker - INFO -       Start worker at:     tcp://172.26.1.4:33945
2025-02-08 11:01:15,461 - distributed.worker - INFO -          Listening to:     tcp://172.26.1.4:33945
2025-02-08 11:01:15,461 - distributed.worker - INFO -           Worker name:           SLURMCluster-7-3
2025-02-08 11:01:15,461 - distributed.worker - INFO -          dashboard at:           172.26.1.4:41061
2025-02-08 11:01:15,461 - distributed.worker - INFO - Waiting to connect to:   tcp://10.42.239.61:44245
2025-02-08 11:01:15,461 - distributed.worker - INFO - -------------------------------------------------
2025-02-08 11:01:15,461 - distributed.worker - INFO -               Threads:                          2
2025-02-08 11:01:15,465 - distributed.worker - INFO -                Memory:                  18.63 GiB
2025-02-08 11:01:15,465 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-63kj26pm
2025-02-08 11:01:15,465 - distributed.worker - INFO - -------------------------------------------------
2025-02-08 11:01:15,477 - distributed.worker - INFO -       Start worker at:     tcp://172.26.1.4:41493
2025-02-08 11:01:15,477 - distributed.worker - INFO -          Listening to:     tcp://172.26.1.4:41493
2025-02-08 11:01:15,477 - distributed.worker - INFO -           Worker name:           SLURMCluster-7-2
2025-02-08 11:01:15,477 - distributed.worker - INFO -          dashboard at:           172.26.1.4:37293
2025-02-08 11:01:15,477 - distributed.worker - INFO - Waiting to connect to:   tcp://10.42.239.61:44245
2025-02-08 11:01:15,477 - distributed.worker - INFO - -------------------------------------------------
2025-02-08 11:01:15,477 - distributed.worker - INFO -               Threads:                          2
2025-02-08 11:01:15,477 - distributed.worker - INFO -                Memory:                  18.63 GiB
2025-02-08 11:01:15,477 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-l52tpuyl
2025-02-08 11:01:15,477 - distributed.worker - INFO - -------------------------------------------------
2025-02-08 11:01:16,114 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-02-08 11:01:16,115 - distributed.worker - INFO -         Registered to:   tcp://10.42.239.61:44245
2025-02-08 11:01:16,115 - distributed.worker - INFO - -------------------------------------------------
2025-02-08 11:01:16,117 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-02-08 11:01:16,117 - distributed.worker - INFO -         Registered to:   tcp://10.42.239.61:44245
2025-02-08 11:01:16,117 - distributed.worker - INFO - -------------------------------------------------
2025-02-08 11:01:16,118 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-02-08 11:01:16,119 - distributed.worker - INFO -         Registered to:   tcp://10.42.239.61:44245
2025-02-08 11:01:16,119 - distributed.worker - INFO - -------------------------------------------------
2025-02-08 11:01:16,120 - distributed.core - INFO - Starting established connection to tcp://10.42.239.61:44245
2025-02-08 11:01:16,120 - distributed.core - INFO - Starting established connection to tcp://10.42.239.61:44245
2025-02-08 11:01:16,120 - distributed.core - INFO - Starting established connection to tcp://10.42.239.61:44245
2025-02-08 11:01:16,125 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-02-08 11:01:16,126 - distributed.worker - INFO -         Registered to:   tcp://10.42.239.61:44245
2025-02-08 11:01:16,126 - distributed.worker - INFO - -------------------------------------------------
2025-02-08 11:01:16,127 - distributed.core - INFO - Starting established connection to tcp://10.42.239.61:44245
2025-02-08 11:01:16,143 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-02-08 11:01:16,144 - distributed.worker - INFO -         Registered to:   tcp://10.42.239.61:44245
2025-02-08 11:01:16,144 - distributed.worker - INFO - -------------------------------------------------
2025-02-08 11:01:16,144 - distributed.core - INFO - Starting established connection to tcp://10.42.239.61:44245
slurmstepd-node04: error: *** JOB 54895 ON node04 CANCELLED AT 2025-02-08T11:16:38 DUE TO TIME LIMIT ***
